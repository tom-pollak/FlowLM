{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4qAMMPkQhfY"
      },
      "outputs": [],
      "source": [
        "import os, random, itertools, math, torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForMaskedLM,\n",
        "    get_cosine_schedule_with_warmup\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from datasets import load_dataset\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4kbDTS3Qo_a"
      },
      "outputs": [],
      "source": [
        "model_id = \"johnowhitaker/modernbert-diffusion\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "SEP_ID, CLS_ID, MASK_ID = tokenizer.sep_token_id, tokenizer.cls_token_id, tokenizer.mask_token_id\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_id, device_map=device)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7ZwaE3IQzJT",
        "outputId": "840bf369-dd8b-4f62-d043-fa13b712c676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 50368])\n",
            "[CLS]User: Which is the best programming language? \n",
            " Assistant: Python, Python,,,,,, is Python..[SEP]\n"
          ]
        }
      ],
      "source": [
        "# Single forward pass:\n",
        "prompt = \"User: Which is the best programming language? \" + tokenizer.sep_token + \" Assistant:\"\n",
        "prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
        "ans_len = 12\n",
        "ids = [CLS_ID] + prompt_ids + [SEP_ID] + [MASK_ID]*ans_len + [SEP_ID]\n",
        "with torch.no_grad():\n",
        "  outs = model(input_ids=torch.tensor([ids]).to(device)).logits\n",
        "print(outs.shape)\n",
        "out_ids = outs[0].argmax(dim=-1).tolist()\n",
        "print(tokenizer.decode(out_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wadlDG2DUUjX",
        "outputId": "19c7dc92-4e76-4382-dd61-182a8347b921"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(46, device='cuda:0') .\n",
            "tensor(45, device='cuda:0') .\n",
            "tensor(15, device='cuda:0')  is\n",
            "tensor(23, device='cuda:0') .\n",
            "tensor(21, device='cuda:0')  programming\n",
            "tensor(22, device='cuda:0')  languages\n",
            "tensor(16, device='cuda:0')  a\n",
            "tensor(17, device='cuda:0')  best\n",
            "tensor(44, device='cuda:0')  etc\n",
            "tensor(19, device='cuda:0')  for\n",
            "tensor(20, device='cuda:0')  all\n",
            "tensor(43, device='cuda:0') ,\n",
            "tensor(41, device='cuda:0') ,\n",
            "tensor(39, device='cuda:0') ,\n",
            "tensor(18, device='cuda:0')  language\n",
            "tensor(42, device='cuda:0')  Python\n",
            "tensor(38, device='cuda:0')  Java\n",
            "tensor(37, device='cuda:0') ,\n",
            "tensor(40, device='cuda:0')  Java\n",
            "tensor(24, device='cuda:0')  There\n",
            "tensor(25, device='cuda:0')  are\n",
            "tensor(26, device='cuda:0')  many\n",
            "tensor(29, device='cuda:0')  languages\n",
            "tensor(30, device='cuda:0')  languages\n",
            "tensor(28, device='cuda:0')  programming\n",
            "tensor(35, device='cuda:0') ,\n",
            "tensor(32, device='cuda:0')  as\n",
            "tensor(27, device='cuda:0')  popular\n",
            "tensor(31, device='cuda:0')  such\n",
            "tensor(33, device='cuda:0')  C\n",
            "tensor(36, device='cuda:0')  C\n",
            "tensor(34, device='cuda:0') ++\n",
            "[CLS]User: Which is the best programming language? [SEP] Assistant:[SEP] is a best language for all programming languages. There are many popular programming languages languages such as C++, C, Java, Java, Python, etc..[SEP]\n"
          ]
        }
      ],
      "source": [
        "# In a loop, keeping the most confident\n",
        "prompt = \"User: Which is the best programming language? \" + tokenizer.sep_token + \" Assistant:\"\n",
        "prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
        "ans_len = 32\n",
        "outs = None\n",
        "ids = [CLS_ID] + prompt_ids + [SEP_ID] + [MASK_ID]*ans_len + [SEP_ID]\n",
        "for i in range(ans_len):\n",
        "  if i % 4 == 0: # Optional: only run through the model every 4 (i.e. keep the top 4 each forwrd pass)\n",
        "    with torch.no_grad():\n",
        "      outs = model(input_ids=torch.tensor([ids]).to(device)).logits\n",
        "  out_probs = torch.softmax(outs[0], dim=-1)\n",
        "  mask_locs = (torch.tensor(ids) == MASK_ID).nonzero(as_tuple=True)[0]\n",
        "  new_probs = torch.zeros_like(out_probs)\n",
        "  new_probs[mask_locs] = out_probs[mask_locs]\n",
        "  max_probs, max_locs = new_probs.max(dim=-1)\n",
        "  max_loc = max_probs.argmax(dim=-1)\n",
        "  print(max_loc, tokenizer.decode(new_probs[max_loc].argmax().item()))\n",
        "  ids[max_loc] = new_probs[max_loc].argmax().item()\n",
        "print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAj0rtmhYcjF"
      },
      "outputs": [],
      "source": [
        "# Wrapping that in a function\n",
        "def sample(q, ans_len=32):\n",
        "  prompt = f\"User: {q} \" + tokenizer.sep_token + \" Assistant:\"\n",
        "  prompt_ids = tokenizer.encode(prompt, add_special_tokens=False)\n",
        "  ids = [CLS_ID] + prompt_ids + [SEP_ID] + [MASK_ID]*ans_len + [SEP_ID]\n",
        "  for i in range(ans_len):\n",
        "    with torch.no_grad():\n",
        "      outs = model(input_ids=torch.tensor([ids]).to(device)).logits\n",
        "    out_probs = torch.softmax(outs[0], dim=-1)\n",
        "    mask_locs = (torch.tensor(ids) == MASK_ID).nonzero(as_tuple=True)[0]\n",
        "    new_probs = torch.zeros_like(out_probs)\n",
        "    new_probs[mask_locs] = out_probs[mask_locs]\n",
        "    max_probs, max_locs = new_probs.max(dim=-1)\n",
        "    max_loc = max_probs.argmax(dim=-1)\n",
        "    ids[max_loc] = new_probs[max_loc].argmax().item()\n",
        "  return tokenizer.decode(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "HAS20X0oZhw5",
        "outputId": "35f61da0-58df-4a28-c58c-3d801813f248"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS]User: Tell me a fun fact about cows [SEP] Assistant:[SEP], here's a fun fact about cows:\\n\\nThe fact is that cows are the most intelligent animals in the world. They can think and make decisions.[SEP]\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample(\"Tell me a fun fact about cows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "f0S3ZQLNUUnU",
        "outputId": "1351bbcd-00ea-47bb-ea73-528390683d28"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS]User: Tell me a funny joke about lemons [SEP] Assistant:[SEP]\\'s a funny joke about lemons: \"I have a lemonade stand, and I\\'m going to sell lemons.\"\\n Assistant: That\\'s funny.[SEP]'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample(\"Tell me a funny joke about lemons\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "KugOpLPHaQSA",
        "outputId": "56ec3a6a-cdb4-44d6-d5ce-ef3832fc25ca"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS]User: Which OS is best? [SEP] Assistant:[SEP], I don't know. I haven't used them personally. I'm sure there are some that are better than others, but I can't tell you.[SEP]\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample(\"Which OS is best?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "sjnWZdgTmMNL",
        "outputId": "a4394b5a-9390-4a85-a326-b456d4c4fac5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[CLS]User: Tell me a fun fact about cows - a good one [SEP] Assistant:[SEP]'s a fun fact about cows: they can't read.\\n\\nComment: I'm sorry, but I can't help you with that one, either.[SEP]\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample(\"Tell me a fun fact about cows - a good one\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
